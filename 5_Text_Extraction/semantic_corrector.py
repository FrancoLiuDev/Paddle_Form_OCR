#!/usr/bin/env python3
"""
OCR èªæ„æ ¡æ­£å·¥å…·
ä½¿ç”¨å¤šç¨®ç­–ç•¥ä¿®æ­£ OCR èª¤è­˜åˆ¥çš„æ–‡å­—
"""

import json
import re
from typing import Dict, List, Tuple, Optional
from difflib import get_close_matches


class SemanticCorrector:
    """OCR èªæ„æ ¡æ­£å™¨"""
    
    def __init__(self):
        # ç­–ç•¥ 1: å¸¸è¦‹èª¤è­˜åˆ¥å­—å…¸ï¼ˆå½¢è¿‘å­—ï¼‰
        self.similar_chars = {
            # å¸¸è¦‹ OCR éŒ¯èª¤
            'ç¨ ': 'ç¨±',  # å°è¡¨æ©Ÿåç¨± â†’ å°è¡¨æ©Ÿåç¨ 
            'èµ‹': 'è™Ÿ',  # åºè™Ÿ â†’ åºèµ‹
            'ç¢': 'æ™‚',  # æ™‚é–“ â†’ ç¢é–“
            'å¦¨': 'é˜²',  # é˜²ç«ç‰† â†’ å¦¨ç«ç‰†
            'æª': 'æ§',  # æ§æ¢° â†’ æªæ¢°
            'æ ½': 'è¼‰',  # ä¸‹è¼‰ â†’ ä¸‹æ ½
            'é£©': 'æ²Œ',  # æ··æ²Œ â†’ æ··é£©
            '0': 'O',   # æ•¸å­— 0 vs å­—æ¯ Oï¼ˆä¾ä¸Šä¸‹æ–‡ï¼‰
            'O': '0',   # å­—æ¯ O vs æ•¸å­— 0ï¼ˆä¾ä¸Šä¸‹æ–‡ï¼‰
            '1': 'I',   # æ•¸å­— 1 vs å­—æ¯ Iï¼ˆä¾ä¸Šä¸‹æ–‡ï¼‰
            'I': '1',   # å­—æ¯ I vs æ•¸å­— 1ï¼ˆä¾ä¸Šä¸‹æ–‡ï¼‰
        }
        
        # ç­–ç•¥ 2: é ˜åŸŸå°ˆç”¨è©å…¸ï¼ˆæ­£ç¢ºçš„å°ˆæ¥­è¡“èªï¼‰
        self.domain_terms = {
            'å°è¡¨æ©Ÿ': ['å°è¡¨æ©Ÿåç¨±', 'å°è¡¨æ©Ÿèªè¨€', 'å°è¡¨æ©Ÿå‹è™Ÿ', 'å°è¡¨æ©Ÿè¨­å®š'],
            'åºè™Ÿ': ['åºè™Ÿ', 'åºåˆ—è™Ÿ', 'æ©Ÿå™¨åºè™Ÿ'],
            'å¼µæ•¸': ['ç¸½å°å¼µæ•¸', 'å½©è‰²å°å¼µæ•¸', 'é»‘ç™½å°å¼µæ•¸', 'åˆ—å°å¼µæ•¸'],
            'ç³»çµ±': ['ç³»çµ±è¨­å®š', 'ç³»çµ±è³‡è¨Š', 'ç³»çµ±ç®¡ç†'],
            'ç¶²è·¯': ['ç¶²è·¯è¨­å®š', 'ç¶²è·¯ä½å€', 'ç¶²è·¯å”å®š'],
            'æ—¥æœŸ': ['æ—¥æœŸæ™‚é–“', 'åˆ—å°æ—¥æœŸ', 'ç³»çµ±æ—¥æœŸ'],
        }
        
        # ç­–ç•¥ 3: ä¸Šä¸‹æ–‡è¦å‰‡ï¼ˆæ ¹æ“šå‰å¾Œæ–‡åˆ¤æ–·ï¼‰
        self.context_rules = [
            # (pattern, wrong, correct, description)
            (r'å°è¡¨.*åç¨ ', 'ç¨ ', 'ç¨±', 'å°è¡¨æ©Ÿåç¨±ä¸­çš„ç¨ æ‡‰ç‚ºç¨±'),
            (r'åºèµ‹', 'èµ‹', 'è™Ÿ', 'åºè™Ÿä¸­çš„èµ‹æ‡‰ç‚ºè™Ÿ'),
            (r'æ—¥æœŸ.*ç‰¹ç¢', 'ç¢', 'æ™‚', 'æ—¥æœŸæ™‚é–“ä¸­çš„ç¢æ‡‰ç‚ºæ™‚'),
            (r'é»‘ç™½å°æ¬¡', 'æ¬¡', 'å¼µæ•¸', 'å°å¼µæ•¸ä¸­çš„æ¬¡æ‡‰ç‚ºå¼µæ•¸'),
        ]
        
        # ç­–ç•¥ 4: æ•¸å­—/å­—æ¯æ··æ·†æª¢æ¸¬
        self.number_letter_patterns = {
            'serial': r'[A-Z]{2}\d+',  # åºè™Ÿæ ¼å¼ï¼šå…©å€‹å¤§å¯«å­—æ¯ + æ•¸å­—
            'ip': r'\d+\.\d+\.\d+\.\d+',  # IP æ ¼å¼
            'date': r'\d{2,4}[/-]\d{1,2}[/-]\d{1,2}',  # æ—¥æœŸæ ¼å¼
            'model': r'[A-Z]\d{3}',  # å‹è™Ÿæ ¼å¼
        }
    
    def correct_similar_chars(self, text: str, context: str = '') -> Tuple[str, List[str]]:
        """
        ç­–ç•¥ 1: ä¿®æ­£å½¢è¿‘å­—
        
        Args:
            text: è¦ä¿®æ­£çš„æ–‡å­—
            context: ä¸Šä¸‹æ–‡ï¼ˆå¯é¸ï¼‰
        
        Returns:
            (ä¿®æ­£å¾Œçš„æ–‡å­—, ä¿®æ­£è¨˜éŒ„åˆ—è¡¨)
        """
        corrections = []
        result = text
        
        for wrong, correct in self.similar_chars.items():
            if wrong in result:
                # æª¢æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦æ”¯æŒæ­¤ä¿®æ­£
                if context:
                    # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼Œé€²è¡Œæ›´æ™ºèƒ½çš„åˆ¤æ–·
                    result_with_context = result.replace(wrong, correct)
                    if self._is_valid_in_context(result_with_context, context):
                        corrections.append(f'å½¢è¿‘å­—: "{wrong}" â†’ "{correct}"')
                        result = result_with_context
                else:
                    corrections.append(f'å½¢è¿‘å­—: "{wrong}" â†’ "{correct}"')
                    result = result.replace(wrong, correct)
        
        return result, corrections
    
    def correct_domain_terms(self, text: str) -> Tuple[str, List[str]]:
        """
        ç­–ç•¥ 2: ä½¿ç”¨é ˜åŸŸè©å…¸ä¿®æ­£å°ˆæ¥­è¡“èª
        
        Returns:
            (ä¿®æ­£å¾Œçš„æ–‡å­—, ä¿®æ­£è¨˜éŒ„åˆ—è¡¨)
        """
        corrections = []
        result = text
        
        # å»ºç«‹å®Œæ•´çš„è¡“èªåˆ—è¡¨
        all_terms = []
        for terms_list in self.domain_terms.values():
            all_terms.extend(terms_list)
        
        # å°‹æ‰¾ç›¸ä¼¼çš„æ­£ç¢ºè¡“èª
        for term in all_terms:
            # è¨ˆç®—ç›¸ä¼¼åº¦
            if self._fuzzy_match(text, term, threshold=0.7):
                if text != term:
                    corrections.append(f'è¡“èªä¿®æ­£: "{text}" â†’ "{term}"')
                    result = term
                    break
        
        return result, corrections
    
    def correct_by_context(self, text: str, prev_text: str = '', next_text: str = '') -> Tuple[str, List[str]]:
        """
        ç­–ç•¥ 3: æ ¹æ“šä¸Šä¸‹æ–‡è¦å‰‡ä¿®æ­£
        
        Args:
            text: è¦ä¿®æ­£çš„æ–‡å­—
            prev_text: å‰ä¸€å€‹æ–‡å­—å€å¡Š
            next_text: å¾Œä¸€å€‹æ–‡å­—å€å¡Š
        
        Returns:
            (ä¿®æ­£å¾Œçš„æ–‡å­—, ä¿®æ­£è¨˜éŒ„åˆ—è¡¨)
        """
        corrections = []
        result = text
        
        # çµ„åˆä¸Šä¸‹æ–‡
        context = f"{prev_text} {text} {next_text}"
        
        for pattern, wrong, correct, description in self.context_rules:
            if re.search(pattern, context):
                if wrong in result:
                    corrections.append(f'ä¸Šä¸‹æ–‡: {description}')
                    result = result.replace(wrong, correct)
        
        return result, corrections
    
    def correct_number_letter_confusion(self, text: str, field_type: str = 'auto') -> Tuple[str, List[str]]:
        """
        ç­–ç•¥ 4: ä¿®æ­£æ•¸å­—/å­—æ¯æ··æ·†
        
        Args:
            text: è¦ä¿®æ­£çš„æ–‡å­—
            field_type: æ¬„ä½é¡å‹ ('serial', 'ip', 'date', 'model', 'auto')
        
        Returns:
            (ä¿®æ­£å¾Œçš„æ–‡å­—, ä¿®æ­£è¨˜éŒ„åˆ—è¡¨)
        """
        corrections = []
        result = text
        
        # è‡ªå‹•åµæ¸¬é¡å‹
        if field_type == 'auto':
            for ptype, pattern in self.number_letter_patterns.items():
                if re.search(pattern, text):
                    field_type = ptype
                    break
        
        # æ ¹æ“šé¡å‹ä¿®æ­£
        if field_type == 'serial':
            # åºè™Ÿï¼šå‰å…©å€‹æ‡‰è©²æ˜¯å­—æ¯ï¼Œå¾Œé¢æ˜¯æ•¸å­—
            if len(text) >= 3:
                # ä¿®æ­£å‰å…©å€‹å­—ç¬¦ç‚ºå­—æ¯
                first_two = text[:2]
                rest = text[2:]
                
                first_two_corrected = first_two.replace('0', 'O').replace('1', 'I')
                rest_corrected = rest.replace('O', '0').replace('I', '1').replace('l', '1')
                
                result = first_two_corrected + rest_corrected
                if result != text:
                    corrections.append(f'åºè™Ÿæ ¼å¼: "{text}" â†’ "{result}"')
        
        elif field_type == 'ip' or field_type == 'date':
            # IP å’Œæ—¥æœŸæ‡‰è©²éƒ½æ˜¯æ•¸å­—
            result = text.replace('O', '0').replace('I', '1').replace('l', '1')
            if result != text:
                corrections.append(f'{field_type}æ ¼å¼: "{text}" â†’ "{result}"')
        
        return result, corrections
    
    def correct_text(self, text: str, context: Dict = None) -> Dict:
        """
        ç¶œåˆä¿®æ­£ï¼šæ‡‰ç”¨æ‰€æœ‰ç­–ç•¥
        
        Args:
            text: è¦ä¿®æ­£çš„æ–‡å­—
            context: ä¸Šä¸‹æ–‡è³‡è¨Š {
                'prev': 'å‰ä¸€å€‹æ–‡å­—',
                'next': 'å¾Œä¸€å€‹æ–‡å­—',
                'field_name': 'æ¬„ä½åç¨±',
                'field_type': 'æ¬„ä½é¡å‹'
            }
        
        Returns:
            ä¿®æ­£çµæœå­—å…¸
        """
        if context is None:
            context = {}
        
        original = text
        all_corrections = []
        
        # æ‡‰ç”¨å„ç¨®ç­–ç•¥
        text, corr1 = self.correct_similar_chars(text, context.get('field_name', ''))
        all_corrections.extend(corr1)
        
        text, corr2 = self.correct_domain_terms(text)
        all_corrections.extend(corr2)
        
        text, corr3 = self.correct_by_context(
            text,
            context.get('prev', ''),
            context.get('next', '')
        )
        all_corrections.extend(corr3)
        
        text, corr4 = self.correct_number_letter_confusion(
            text,
            context.get('field_type', 'auto')
        )
        all_corrections.extend(corr4)
        
        return {
            'original': original,
            'corrected': text,
            'changed': original != text,
            'corrections': all_corrections
        }
    
    def correct_ocr_result(self, json_file: str, output_file: str = None) -> Dict:
        """
        ä¿®æ­£æ•´å€‹ OCR çµæœæª”æ¡ˆ
        
        Args:
            json_file: OCR çµæœ JSON æª”æ¡ˆ
            output_file: è¼¸å‡ºæª”æ¡ˆï¼ˆå¯é¸ï¼‰
        
        Returns:
            ä¿®æ­£çµ±è¨ˆ
        """
        # è®€å– OCR çµæœ
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        text_blocks = data.get('text_blocks', [])
        total_corrections = 0
        correction_details = []
        
        # é€å€‹ä¿®æ­£
        for i, block in enumerate(text_blocks):
            text = block['text']
            
            # æº–å‚™ä¸Šä¸‹æ–‡
            context = {
                'prev': text_blocks[i-1]['text'] if i > 0 else '',
                'next': text_blocks[i+1]['text'] if i < len(text_blocks)-1 else ''
            }
            
            # ä¿®æ­£
            result = self.correct_text(text, context)
            
            if result['changed']:
                block['original_text'] = result['original']
                block['text'] = result['corrected']
                block['corrections'] = result['corrections']
                total_corrections += 1
                
                correction_details.append({
                    'index': i,
                    'original': result['original'],
                    'corrected': result['corrected'],
                    'corrections': result['corrections']
                })
        
        # å„²å­˜çµæœ
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        
        return {
            'total_blocks': len(text_blocks),
            'corrected_blocks': total_corrections,
            'correction_rate': f'{total_corrections/len(text_blocks)*100:.1f}%' if text_blocks else '0%',
            'details': correction_details
        }
    
    def _fuzzy_match(self, text1: str, text2: str, threshold: float = 0.7) -> bool:
        """æ¨¡ç³ŠåŒ¹é…"""
        from difflib import SequenceMatcher
        similarity = SequenceMatcher(None, text1, text2).ratio()
        return similarity >= threshold
    
    def _is_valid_in_context(self, text: str, context: str) -> bool:
        """æª¢æŸ¥ä¿®æ­£å¾Œçš„æ–‡å­—åœ¨ä¸Šä¸‹æ–‡ä¸­æ˜¯å¦åˆç†"""
        # ç°¡å–®çš„æª¢æŸ¥ï¼šçœ‹ä¿®æ­£å¾Œçš„æ–‡å­—æ˜¯å¦åœ¨é ˜åŸŸè©å…¸ä¸­
        for terms_list in self.domain_terms.values():
            if any(term in text for term in terms_list):
                return True
        return False


def demo():
    """ç¤ºç¯„èªæ„æ ¡æ­£åŠŸèƒ½"""
    
    corrector = SemanticCorrector()
    
    print('='*70)
    print('ğŸ”§ OCR èªæ„æ ¡æ­£å·¥å…·ç¤ºç¯„')
    print('='*70)
    print()
    
    # æ¸¬è©¦æ¡ˆä¾‹
    test_cases = [
        {
            'text': 'å°è¡¨åç¨ ',
            'context': {'field_name': 'å°è¡¨æ©Ÿ'},
            'description': 'å½¢è¿‘å­—ä¿®æ­£'
        },
        {
            'text': 'åºèµ‹',
            'context': {},
            'description': 'å½¢è¿‘å­—ä¿®æ­£'
        },
        {
            'text': 'é»‘ç™½å°æ¬¡',
            'context': {'prev': 'å½©è‰²å°å¼µæ•¸', 'next': '294é¡µ'},
            'description': 'ä¸Šä¸‹æ–‡ä¿®æ­£'
        },
        {
            'text': 'NC7OO3677',  # O æ‡‰è©²æ˜¯ 0
            'context': {'field_type': 'serial'},
            'description': 'æ•¸å­—/å­—æ¯æ··æ·†'
        },
        {
            'text': 'æ—¥æœŸ/ç‰¹ç¢',
            'context': {},
            'description': 'å½¢è¿‘å­—ä¿®æ­£'
        },
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f'ğŸ“Œ æ¸¬è©¦ {i}: {case["description"]}')
        print(f'   åŸå§‹: "{case["text"]}"')
        
        result = corrector.correct_text(case['text'], case['context'])
        
        if result['changed']:
            print(f'   âœ… ä¿®æ­£: "{result["corrected"]}"')
            for correction in result['corrections']:
                print(f'      â€¢ {correction}')
        else:
            print(f'   â„¹ï¸  ç„¡éœ€ä¿®æ­£')
        print()
    
    # æ¸¬è©¦å®Œæ•´ OCR æª”æ¡ˆä¿®æ­£
    print('='*70)
    print('ğŸ“„ æ¸¬è©¦å®Œæ•´æª”æ¡ˆä¿®æ­£')
    print('='*70)
    print()
    
    ocr_file = '../4_OCR_Recognition/result/result_fuji.json'
    output_file = '../4_OCR_Recognition/result/result_fuji_corrected.json'
    
    try:
        stats = corrector.correct_ocr_result(ocr_file, output_file)
        
        print(f'ç¸½å€å¡Šæ•¸: {stats["total_blocks"]}')
        print(f'ä¿®æ­£å€å¡Šæ•¸: {stats["corrected_blocks"]}')
        print(f'ä¿®æ­£ç‡: {stats["correction_rate"]}')
        print()
        
        if stats['details']:
            print('ä¿®æ­£è©³æƒ…ï¼ˆå‰ 5 å€‹ï¼‰:')
            for detail in stats['details'][:5]:
                print(f'  â€¢ ç´¢å¼• {detail["index"]}: "{detail["original"]}" â†’ "{detail["corrected"]}"')
                for corr in detail['corrections']:
                    print(f'    - {corr}')
        
        print()
        print(f'âœ… ä¿®æ­£çµæœå·²å„²å­˜è‡³: {output_file}')
        
    except FileNotFoundError:
        print(f'âš ï¸  æ‰¾ä¸åˆ°æª”æ¡ˆ: {ocr_file}')
        print('   è«‹å…ˆåŸ·è¡Œ OCR è­˜åˆ¥')
    
    print()
    print('='*70)
    print('âœ¨ ç¤ºç¯„å®Œæˆ')
    print('='*70)


if __name__ == '__main__':
    demo()
